{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e60c61a",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an \n",
    "example of each."
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ca046c7",
   "metadata": {},
   "source": [
    "->Simple linear regression has only one x and one y variable. \n",
    "- For instance, when we predict rent based on square feet alone that is simple linear regression.\n",
    "->Multiple linear regression has one y and two or more x variables.\n",
    "- For instance, when we predict rent based on square feet and numer of rooms that is simple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d35739",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in \n",
    "a given dataset?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "244a8a98",
   "metadata": {},
   "source": [
    "-> There is a linear relationship between the predictors (x) and the outcome (y)\n",
    "1. Predictors (x) are independent and observed with negligible error\n",
    "2. Residual Errors have a mean value of zero\n",
    "3. Residual Errors have constant variance\n",
    "4. Residual Errors are independent from each other and predictors (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea43575",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using \n",
    "a real-world scenario."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6457ecd",
   "metadata": {},
   "source": [
    "-> understanding of slope-intercept:    \n",
    "The easiest way to understand and interpret slope and intercept in linear models is to first understand the slope-intercept formula: y = mx + b. M is the slope or the consistent change between x and y, and b is the y-intercept. \n",
    "Often, the y-intercept represents the starting point of the equation.\n",
    "\n",
    "-> How to interpret the slope on a simple linear regression model?\n",
    "If the slope of the line is positive, then there is a positive linear relationship, i.e., as one increases, the other increases. \n",
    "If the slope is negative, then there is a negative linear relationship, i.e., as one increases the other variable decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c18127e",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd908ee0",
   "metadata": {},
   "source": [
    "Gradient descent is an optimization algorithm which is commonly-used to train machine learning models and neural networks. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9ca75",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2183922",
   "metadata": {},
   "source": [
    "Multiple linear regression has one y and two or more x variables, where as Simple linear regression has only one x and one y variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3a1195",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and \n",
    "address this issue?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa3d4971",
   "metadata": {},
   "source": [
    "-> multicollinearity in multiple linear regression:\n",
    "    \n",
    "--Multicollinearity exists whenever an independent variable is highly correlated with one or more of the other independent variables in a multiple regression equation. \n",
    "Multicollinearity is a problem because it will make the statistical inferences less reliable.\n",
    "\n",
    "--Multicollinearity occurs when independent variables in a regression model are correlated. \n",
    "This correlation is a problem because independent variables should be independent. \n",
    "If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.\n",
    "\n",
    "->The potential solutions include the following:\n",
    "1. Remove some of the highly correlated independent variables.\n",
    "2. Linearly combine the independent variables, such as adding them together.\n",
    "3. Partial least squares regression uses principal component analysis to create a set of uncorrelated components to include in the model.\n",
    "4. LASSO and Ridge regression are advanced forms of regression analysis that can handle multicollinearity. If you know how to perform linear least squares regression, youâ€™ll be able to handle these analyses with just a little additional study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03724249",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd4901b8",
   "metadata": {},
   "source": [
    "Polynomial regression is a form of Linear regression where only due to the Non-linear relationship between dependent and independent variables, we add some polynomial terms to linear regression to convert it into Polynomial regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d2d0a",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear \n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "235a5b11",
   "metadata": {},
   "source": [
    "-> Advantages of polynomial regression compared to linear regression:\n",
    "    Polynomial regression is a special case of multiple linear regression. \n",
    "    The relationship between the independent variable x and dependent variable y is modeled as an nth degree polynomial in x. \n",
    "    Linear regression cannot be used to fit non-linear data (underfitting).\n",
    "-> DisAdvantages of polynomial regression compared to linear regression:    \n",
    "    One or two outliers in the data might have a significant impact on the nonlinear analysis' outcomes. \n",
    "    These are overly reliant on outliers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
